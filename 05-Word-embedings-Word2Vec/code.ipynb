{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http://nilc.icmc.usp.br/nilc/index.php/repositorio-de-word-embeddings-do-nilc\n",
    "\n",
    "!unzip \"/content/drive/MyDrive/Colab Notebooks/Word2Vec/cbow_s300.zip\"\n",
    "\n",
    "import pandas as pd\n",
    "artigo_treino = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Word2Vec/treino.csv\")\n",
    "artigo_teste = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Word2Vec/teste.csv\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "texto = [\n",
    "    \"Este produto é muito bom\",\n",
    "    \"Este produto é muito ruim\"\n",
    "]\n",
    "\n",
    "vetorizador = CountVectorizer()\n",
    "vetorizador.fit(texto)\n",
    "print(vetorizador.vocabulary_)\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "modelo = KeyedVectors.load_word2vec_format(\"cbow_s300.txt\")\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "nltk.download('punkt')\n",
    "\n",
    "def tokenizador(texto):\n",
    "  texto = texto.lower()\n",
    "  lista_alfanumerico = []\n",
    "\n",
    "  for token_valido in nltk.word_tokenize(texto):\n",
    "    if token_valido in string.punctuation: continue\n",
    "    lista_alfanumerico.append(token_valido)\n",
    "  \n",
    "  return lista_alfanumerico\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "nltk.download('punkt')\n",
    "\n",
    "def tokenizador(texto):\n",
    "  texto = texto.lower()\n",
    "  lista_alfanumerico = []\n",
    "\n",
    "  for token_valido in nltk.word_tokenize(texto):\n",
    "    if token_valido in string.punctuation: continue\n",
    "    lista_alfanumerico.append(token_valido)\n",
    "  \n",
    "  return lista_alfanumerico\n",
    "\n",
    "def matriz_vetores(textos):\n",
    "  x = len(textos)\n",
    "  y = 300\n",
    "  matriz = np.zeros((x,y))\n",
    "\n",
    "  for i in range(x):\n",
    "    palavras_numeros = tokenizador(textos.iloc[i])\n",
    "    matriz[i] = combinacao_de_vetores_por_soma(palavras_numeros)\n",
    "\n",
    "  return matriz\n",
    "\n",
    "matriz_vetores_treino = matriz_vetores(artigo_treino.title)\n",
    "matriz_vetores_teste = matriz_vetores(artigo_teste.title)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "LR = LogisticRegression(max_iter = 200)\n",
    "LR.fit(matriz_vetores_treino, artigo_treino.category)\n",
    "label_prevista = LR.predict(matriz_vetores_teste)\n",
    "CR = classification_report(artigo_teste.category, label_prevista)\n",
    "print(CR)\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "DC = DummyClassifier()\n",
    "DC.fit(matriz_vetores_treino, artigo_treino.category)\n",
    "label_previsao_dc = DC.predict(matriz_vetores_teste)\n",
    "CR_dummy = classification_report(artigo_teste.category, label_previsao_dc)\n",
    "print(CR_dummy)\n",
    "\n",
    "modelo_skipgram = KeyedVectors.load_word2vec_format(\"skip_s300.txt\")\n",
    "\n",
    "def combinacao_de_vetores_por_soma_skipgram(palavras_numeros):\n",
    "  vetor_resultante = np.zeros(300)\n",
    "  for pn in palavras_numeros:\n",
    "    try:\n",
    "      vetor_resultante =+ modelo_skipgram.get_vector(pn)\n",
    "    except KeyError:\n",
    "      if pn.isnumeric():\n",
    "        pn = \"0\"*len(pn)\n",
    "        vetor_resultante =+ modelo_skipgram.get_vector(pn)\n",
    "      else:\n",
    "        vetor_resultante =+ modelo_skipgram.get_vector('unknown')\n",
    "  return vetor_resultante\n",
    "\n",
    "def matriz_vetores_skipgram(textos):\n",
    "  x = len(textos)\n",
    "  y = 300\n",
    "  matriz = np.zeros((x,y))\n",
    "\n",
    "  for i in range(x):\n",
    "    palavras_numeros = tokenizador(textos.iloc[i])\n",
    "    matriz[i] = combinacao_de_vetores_por_soma_skipgram(palavras_numeros)\n",
    "\n",
    "matriz_vetores_treino_skipgram = matriz_vetores_skipgram(artigo_treino.title)\n",
    "matriz_vetores_teste_skipgram = matriz_vetores_skipgram(artigo_teste.title)\n",
    "\n",
    "LR_skipgram = LogisticRegression(max_iter = 200)\n",
    "LR_skipgram.fit(matriz_vetores_treino_skipgram, artigo_treino.category)\n",
    "label_previsao_skipgram = LR_skipgram.predict(matriz_vetores_teste_skipgram)\n",
    "CR_skipgram = classification_report(artigo_teste.category, label_previsao_skipgram)\n",
    "print(CR_skipgram)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
